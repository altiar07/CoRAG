# CoRAG â€“ Contextual Retrieval-Augmented Generation

CoRAG is an experimental pipeline for **improving Retrieval-Augmented Generation (RAG)** systems.  
The idea: instead of a naive â€œretrieve and dump into LLMâ€ approach, CoRAG adds contextual steps like query rewriting, multi-hop retrieval, and reranking to make responses more accurate and less noisy.   

---

## Why CoRAG?
Most RAG implementations fail in two common cases:
1. **Weak queries** â†’ the retriever doesnâ€™t return anything useful.  
2. **Shallow retrieval** â†’ the answer requires reasoning over multiple chunks.  

CoRAG tries to address these with:
- Query rewriting (LLM reformulates weak/underspecified questions).  
- Multi-hop retrieval (re-queries with intermediate results).  
- Confidence scoring (â€œI donâ€™t knowâ€ when retrieval is weak).  
- Embedding + reranker experiments.  

---

## Current Status
**Baseline RAG â€“ DONE**
- [x] FAISS retriever with SentenceTransformers (MiniLM baseline).  
- [x] Local LLM integration (Phi-3 via `llama-cpp-python`, Q4 quantized).  
- [x] End-to-end pipeline with PDF ingestion (manual run).  
- [x] Interactive terminal chat (no reloading the model each time).  
- [ ] Batch PDF ingestion â†’ next step.  

Next up: **CoRAG Foundations**
- Query rewriter module.  
- Multi-hop retrieval loop.  
- Benchmark baseline RAG vs CoRAG on a sample dataset.  

---

## Project Structure
```
CoRAG/
â”œâ”€â”€ data/                # PDFs and datasets
â”œâ”€â”€ models/              # locally stored LLM weights
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ retriever.py     # FAISS integration
â”‚   â”œâ”€â”€ generator.py     # llama-cpp wrapper
â”‚   â”œâ”€â”€ corag_chain.py   # RAG pipeline orchestration
â”‚   â””â”€â”€ utils.py         # helpers (chunking, preprocessing)
â””â”€â”€ README.md
```

---

## Setup

### Requirements
- Python 3.10+
- `pip install -r requirements.txt`
- Local LLM weights (https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)  
- FAISS, SentenceTransformers, llama-cpp-python

### Run
```bash
# Ingest PDF into FAISS
python src/retriever.py --ingest data/sample.pdf

# Start RAG chat loop
python src/pipeline.py
```

---

## Roadmap

- 1: Baseline RAG (done)  
- 2: CoRAG (query rewriting, multi-hop retrieval)  
- 3: Scaling (GPU offload, Kaggle tests on 7B+ models)  
- 4: Robustness (confidence scoring, reranker, embeddings benchmark)  
- 5: API & UI (FastAPI backend + Streamlit/Gradio)  
- 6: Evaluation & Docs (benchmarks, Hugging Face demo, full docs)  

---

## References
- [SentenceTransformers](https://www.sbert.net/)  
- [FAISS](https://faiss.ai/)  
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python)  
- [RAG Survey (Lewis et al., 2020)](https://arxiv.org/abs/2005.11401)  

---

## ğŸ‘¤ Author
Tushar Ranjan â€“ MSc Embedded Systems @ University of Freiburg
