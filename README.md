# CoRAG Demo â€“ Baseline RAG Implementation

This repository contains the **baseline Retrieval-Augmented Generation (RAG)** pipeline that will be extended into a full **Chain-of-Retrieval Augmented Generation (CoRAG)** system.

The goal is to demonstrate **multi-hop retrieval and reasoning** with a local LLM running on Apple Silicon (M1/M2) using [`llama-cpp-python`](https://github.com/abetlen/llama-cpp-python) and quantized GGUF models.

---

## ðŸ“‚ Project Structure

```plaintext
corag-demo/
â”‚â”€â”€ data/                 # Sample docs (domain PDFs, txt files)
â”‚   â””â”€â”€ sample_docs.txt
â”‚â”€â”€ models/               # Quantized GGUF model files
â”‚   â””â”€â”€ phi-3-mini-4k-instruct.Q4_K_M.gguf
â”‚â”€â”€ notebooks/            # For experiments & prototyping
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ retriever.py       # Document embedding & retrieval
â”‚   â”œâ”€â”€ generator.py       # LLM interface
â”‚   â”œâ”€â”€ corag_chain.py     # Multi-step retrieval logic (to be built)
â”‚   â”œâ”€â”€ evaluator.py       # Benchmark & evaluation functions
â”‚   â””â”€â”€ utils.py           # Helper functions
â”‚â”€â”€ app.py                 # Streamlit/Gradio demo
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
